* Write some documentation, including a manual page.

* Better logging, in particular of network activity.  Final URLs after
  redirection should be included in error messages.

* Better XML error handling.  On an Expat error, report the XML
  fragment immediately before and after the error (which should still
  be available in the input buffer).  Consider exporting position
  information in expat_source, and a stack of open tags.  (Hopefully,
  this will not cause too much of a slowdown.)

* Extract requires/provides/conflicts/obsoletes and store them in a
  database table (or multiple tables, not clear what would be the best
  approach).

* Parallelize downloading.

* Extend Java support: extract method, field references and
  definitions.  Recursively descend into WAR and EAR archives and
  process classes found there.

* Support for extracting Python symbols.  This probably needs flow
  analysis to give good results.

* Parallelize RPM parsing and database loading.  It is not entirely
  clear if this is beneficial on small systems, but it will probably
  help if symboldb ever runs on real server systems.

* Support unattended operation.  The package set <-> compose URL
  mapping should probably reside in the database, and a single command
  (which can be run from cron) could use that to update all package
  sets.  This also relies on better logging/diagnostics and improved
  error recovery.

* More test cases, including loading of sample RPMs.

* Accelerate downloads of re-signed RPMs by combining the new header
  with the existing compressed cpio data.

* Use the libpq binary interface for bulk data transfers.  This should
  lead to a measurable speedup when transferring mostly integer
  columns (e.g., when computing the ELF closure).

* Retry database transactions on unique constraint failures.  This
  means re-opening the RPM file and re-start processing, expecting
  that the race condition will not reappear (because the row is now
  present).
